{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load data\n",
        "data = pd.read_excel('/content/supplier data.xlsx', sheet_name='Supplier Quality')\n",
        "\n",
        "# Create reliability label (1 = Reliable, 0 = Unreliable)\n",
        "threshold = data['Total Defect Qty'].median()\n",
        "data['Reliability'] = (data['Total Defect Qty'] < threshold).astype(int)\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = ['Plant Location', 'Category', 'Material Type']\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Features and target\n",
        "X = data[categorical_cols]\n",
        "y = data['Reliability']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Model Evaluation:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display valid options for cold-start prediction\n",
        "print(\"\\nValid categories for cold-start prediction:\")\n",
        "for col in categorical_cols:\n",
        "    unique_labels = label_encoders[col].classes_\n",
        "    print(f\"- {col}: {list(unique_labels)}\")\n",
        "\n",
        "# Example: Predict new supplier (using a valid existing sample)\n",
        "sample = data.iloc[0]\n",
        "new_supplier = pd.DataFrame({\n",
        "    'Plant Location': [sample['Plant Location']],\n",
        "    'Category': [sample['Category']],\n",
        "    'Material Type': [sample['Material Type']],\n",
        "})\n",
        "\n",
        "predicted_label = model.predict(new_supplier)[0]\n",
        "result = 'Reliable' if predicted_label == 1 else 'Unreliable'\n",
        "print(f\"\\nNew Supplier Predicted Reliability: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyNqed1-9BTJ",
        "outputId": "08d587c2-f8df-4dec-b021-4bcc4cbb92e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.49      0.49       514\n",
            "           1       0.50      0.49      0.49       532\n",
            "\n",
            "    accuracy                           0.49      1046\n",
            "   macro avg       0.49      0.49      0.49      1046\n",
            "weighted avg       0.49      0.49      0.49      1046\n",
            "\n",
            "\n",
            "Valid categories for cold-start prediction:\n",
            "- Plant Location: ['Barling', 'Bloomingdale', 'Bruce Crossing', 'Charles City', 'Charlevoix', 'Chatham', 'Chesaning', 'Clarksville', 'Clay', 'Climax', 'Cottonwood', 'De Ruyter', 'Florence', 'Frazer', 'Garwood', 'Henning', 'Hingham', 'Jordan Valley', 'June Lake', 'Middletown', 'New Britain', 'Prescott', 'Reading', 'Ripton', 'Riverside', 'Savannah', 'Twin Rocks', 'Waldoboro', 'Weaverville', 'Westside']\n",
            "- Category: ['Electrical', 'Goods & Services', 'Logistics', 'Materials & Components', 'Mechanicals', 'Packaging']\n",
            "- Material Type: ['Batteries', 'Carton', 'Composites', 'Controllers', 'Corrugate', 'Crates', 'Drives', 'Electrolytes', 'Film', 'Glass', 'Hardware', 'Labels', 'Mechanicals', 'Molds', 'Motors', 'Packaging', 'Printed Materials', 'Pump', 'Raw Materials', 'Tape', 'Valves', 'Wires']\n",
            "\n",
            "New Supplier Predicted Reliability: Unreliable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load data\n",
        "data = pd.read_excel('supplier data.xlsx', sheet_name='Supplier Quality')\n",
        "\n",
        "# Extract date-based features\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "\n",
        "# Create reliability label based solely on historical Total Defect Qty\n",
        "threshold = data['Total Defect Qty'].median()\n",
        "data['Reliability'] = (data['Total Defect Qty'] < threshold).astype(int)\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = ['Plant Location', 'Category', 'Material Type']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Use only intrinsic and time-based features (no defect info)\n",
        "feature_cols = ['Plant Location', 'Category', 'Material Type', 'Year', 'Month', 'DayOfWeek']\n",
        "\n",
        "X = data[feature_cols]\n",
        "y = data['Reliability']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=10)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Cold-Start Model Evaluation:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Example: Predict new cold-start supplier\n",
        "sample = data.iloc[0]\n",
        "new_supplier = pd.DataFrame({\n",
        "    'Plant Location': [sample['Plant Location']],\n",
        "    'Category': [sample['Category']],\n",
        "    'Material Type': [sample['Material Type']],\n",
        "    'Year': [sample['Year']],\n",
        "    'Month': [sample['Month']],\n",
        "    'DayOfWeek': [sample['DayOfWeek']],\n",
        "})\n",
        "\n",
        "predicted_label = model.predict(new_supplier)[0]\n",
        "result = 'Reliable' if predicted_label == 1 else 'Unreliable'\n",
        "print(f\"\\nNew Supplier Predicted Reliability (cold-start): {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKa6bDhO94Ov",
        "outputId": "4b571cbe-ac53-464f-be86-05b5f2a280f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cold-Start Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.52      0.51       514\n",
            "           1       0.52      0.50      0.51       532\n",
            "\n",
            "    accuracy                           0.51      1046\n",
            "   macro avg       0.51      0.51      0.51      1046\n",
            "weighted avg       0.51      0.51      0.51      1046\n",
            "\n",
            "\n",
            "New Supplier Predicted Reliability (cold-start): Unreliable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load data\n",
        "data = pd.read_excel('supplier data.xlsx', sheet_name='Supplier Quality')\n",
        "\n",
        "# Extract date-based features\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "\n",
        "# Create reliability label\n",
        "threshold = data['Total Defect Qty'].median()\n",
        "data['Reliability'] = (data['Total Defect Qty'] < threshold).astype(int)\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = ['Plant Location', 'Category', 'Material Type']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Features\n",
        "feature_cols = ['Plant Location', 'Category', 'Material Type', 'Year', 'Month', 'DayOfWeek']\n",
        "X = data[feature_cols]\n",
        "y = data['Reliability']\n",
        "\n",
        "# Step 1: Apply KMeans clustering on features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "data['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster as a feature\n",
        "X['Cluster'] = data['Cluster']\n",
        "\n",
        "# Step 2: Handle imbalance using SMOTE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 3: Train model\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Improved Cold-Start Model Evaluation:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Example cold-start prediction (with cluster assigned)\n",
        "sample = data.iloc[0]\n",
        "sample_features = scaler.transform([[sample['Plant Location'], sample['Category'], sample['Material Type'],\n",
        "                                     sample['Year'], sample['Month'], sample['DayOfWeek']]])\n",
        "sample_cluster = kmeans.predict(sample_features)[0]\n",
        "\n",
        "new_supplier = pd.DataFrame({\n",
        "    'Plant Location': [sample['Plant Location']],\n",
        "    'Category': [sample['Category']],\n",
        "    'Material Type': [sample['Material Type']],\n",
        "    'Year': [sample['Year']],\n",
        "    'Month': [sample['Month']],\n",
        "    'DayOfWeek': [sample['DayOfWeek']],\n",
        "    'Cluster': [sample_cluster],\n",
        "})\n",
        "\n",
        "predicted_label = model.predict(new_supplier)[0]\n",
        "result = 'Reliable' if predicted_label == 1 else 'Unreliable'\n",
        "print(f\"\\nNew Supplier Predicted Reliability (improved): {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lavDROSO-P69",
        "outputId": "c726f23e-746b-42c9-b7a2-d4559e60a89a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2088063469.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Cluster'] = data['Cluster']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved Cold-Start Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.49      0.50       514\n",
            "           1       0.52      0.53      0.52       532\n",
            "\n",
            "    accuracy                           0.51      1046\n",
            "   macro avg       0.51      0.51      0.51      1046\n",
            "weighted avg       0.51      0.51      0.51      1046\n",
            "\n",
            "\n",
            "New Supplier Predicted Reliability (improved): Unreliable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load data\n",
        "data = pd.read_excel('supplier data.xlsx', sheet_name='Supplier Quality')\n",
        "\n",
        "# Extract date-based features\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = ['Plant Location', 'Category', 'Material Type']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Features for clustering\n",
        "feature_cols = ['Plant Location', 'Category', 'Material Type', 'Year', 'Month', 'DayOfWeek']\n",
        "X_features = data[feature_cols]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_features)\n",
        "\n",
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "data['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster as a new feature\n",
        "X_features['Cluster'] = data['Cluster']\n",
        "\n",
        "# Define target\n",
        "threshold = data['Total Defect Qty'].median()\n",
        "data['Reliability'] = (data['Total Defect Qty'] < threshold).astype(int)\n",
        "y = data['Reliability']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Balance dataset with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Cluster-based Cold-Start Model Evaluation:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Example cold-start prediction\n",
        "sample = data.iloc[0]\n",
        "sample_features = scaler.transform([[sample['Plant Location'], sample['Category'],\n",
        "                                     sample['Material Type'], sample['Year'],\n",
        "                                     sample['Month'], sample['DayOfWeek']]])\n",
        "sample_cluster = kmeans.predict(sample_features)[0]\n",
        "\n",
        "new_supplier = pd.DataFrame({\n",
        "    'Plant Location': [sample['Plant Location']],\n",
        "    'Category': [sample['Category']],\n",
        "    'Material Type': [sample['Material Type']],\n",
        "    'Year': [sample['Year']],\n",
        "    'Month': [sample['Month']],\n",
        "    'DayOfWeek': [sample['DayOfWeek']],\n",
        "    'Cluster': [sample_cluster],\n",
        "})\n",
        "\n",
        "predicted_label = model.predict(new_supplier)[0]\n",
        "result = 'Reliable' if predicted_label == 1 else 'Unreliable'\n",
        "print(f\"\\nNew Supplier Predicted Reliability (cluster-based): {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1oFvVLo-f2d",
        "outputId": "53ab4796-3f83-4683-945b-2e73a926de53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-233095039.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_features['Cluster'] = data['Cluster']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster-based Cold-Start Model Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.49      0.50       514\n",
            "           1       0.52      0.53      0.52       532\n",
            "\n",
            "    accuracy                           0.51      1046\n",
            "   macro avg       0.51      0.51      0.51      1046\n",
            "weighted avg       0.51      0.51      0.51      1046\n",
            "\n",
            "\n",
            "New Supplier Predicted Reliability (cluster-based): Unreliable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster_based_coldstart_procurement.py\n",
        "# Run: python cluster_based_coldstart_procurement.py\n",
        "# Requires: pandas, scikit-learn, imbalanced-learn, numpy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ---------- 1) Load dataset ----------\n",
        "FILE = \"/content/Procurement KPI Analysis Dataset.csv\"\n",
        "df = pd.read_csv(FILE)\n",
        "\n",
        "# Quick check (uncomment to print)\n",
        "# print(df.columns)\n",
        "# print(df.head())\n",
        "\n",
        "# ---------- 2) Clean / parse columns ----------\n",
        "# Ensure date columns are datetime\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
        "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], errors='coerce')\n",
        "\n",
        "# Fill or drop rows with critical missing fields:\n",
        "# We will drop rows missing Item_Category or Unit_Price or Quantity as they are essential.\n",
        "df = df.dropna(subset=['Item_Category', 'Quantity', 'Unit_Price'])\n",
        "\n",
        "# ---------- 3) Create cold-start friendly features ----------\n",
        "# Date-derived features (onboarding/time info that can be known)\n",
        "df['Order_Year'] = df['Order_Date'].dt.year.fillna(0).astype(int)\n",
        "df['Order_Month'] = df['Order_Date'].dt.month.fillna(0).astype(int)\n",
        "df['Order_DayOfWeek'] = df['Order_Date'].dt.dayofweek.fillna(0).astype(int)\n",
        "\n",
        "# Price engineering\n",
        "df['Unit_Price'] = pd.to_numeric(df['Unit_Price'], errors='coerce').fillna(df['Unit_Price'].median())\n",
        "df['Negotiated_Price'] = pd.to_numeric(df['Negotiated_Price'], errors='coerce')\n",
        "# If negotiated price is missing, use Unit_Price (safe fallback)\n",
        "df['Negotiated_Price'] = df['Negotiated_Price'].fillna(df['Unit_Price'])\n",
        "df['Price_Diff'] = df['Unit_Price'] - df['Negotiated_Price']\n",
        "df['Price_Ratio'] = df['Negotiated_Price'] / (df['Unit_Price'] + 1e-9)\n",
        "\n",
        "# Quantity\n",
        "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').fillna(df['Quantity'].median())\n",
        "\n",
        "# Drop any remaining rows with NaN in engineered numeric features\n",
        "df = df.dropna(subset=['Unit_Price', 'Negotiated_Price', 'Quantity'])\n",
        "\n",
        "# ---------- 4) Target: Compliance (suitable for reliability) ----------\n",
        "# Map Compliance Yes -> 1 (reliable), No -> 0 (unreliable)\n",
        "# If Compliance column contains other values or NaN, drop or fill with mode\n",
        "if 'Compliance' not in df.columns:\n",
        "    raise KeyError(\"Dataset must contain 'Compliance' column for this pipeline.\")\n",
        "\n",
        "df['Compliance'] = df['Compliance'].astype(str).str.strip().str.lower()\n",
        "# Keep only rows with yes/no; others drop\n",
        "df = df[df['Compliance'].isin(['yes', 'no'])]\n",
        "df['Target'] = (df['Compliance'] == 'yes').astype(int)\n",
        "\n",
        "# ---------- 5) Encode categorical features (cold-start-safe) ----------\n",
        "# We will not use 'Supplier' string directly for cold-start predictions because a new supplier name will be unseen.\n",
        "# Instead we use item-level and price/quantity/date features and add a Cluster feature.\n",
        "\n",
        "cat_col = 'Item_Category'\n",
        "le_cat = LabelEncoder()\n",
        "df[cat_col + '_enc'] = le_cat.fit_transform(df[cat_col].astype(str))\n",
        "\n",
        "# Save list of valid categories for later prediction\n",
        "valid_categories = list(le_cat.classes_)\n",
        "print(\"Valid Item_Category values:\", valid_categories)\n",
        "\n",
        "# ---------- 6) Prepare features for clustering ----------\n",
        "feat_for_cluster = [\n",
        "    cat_col + '_enc',\n",
        "    'Quantity',\n",
        "    'Unit_Price',\n",
        "    'Negotiated_Price',\n",
        "    'Price_Diff',\n",
        "    'Price_Ratio',\n",
        "    'Order_Year',\n",
        "    'Order_Month',\n",
        "    'Order_DayOfWeek'\n",
        "]\n",
        "X_cluster = df[feat_for_cluster].copy()\n",
        "\n",
        "# Standardize for clustering\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "# ---------- 7) KMeans clustering to create supplier profiles ----------\n",
        "# Choose n_clusters reasonably (try 4-8). We'll pick 6 here but you can tune it.\n",
        "n_clusters = 6\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add Cluster to feature set (int)\n",
        "df['Cluster'] = df['Cluster'].astype(int)\n",
        "\n",
        "# ---------- 8) Final feature set for classifier (NO historical defect fields) ----------\n",
        "feature_cols = [\n",
        "    cat_col + '_enc',\n",
        "    'Quantity',\n",
        "    'Unit_Price',\n",
        "    'Negotiated_Price',\n",
        "    'Price_Diff',\n",
        "    'Price_Ratio',\n",
        "    'Order_Year',\n",
        "    'Order_Month',\n",
        "    'Order_DayOfWeek',\n",
        "    'Cluster'\n",
        "]\n",
        "X = df[feature_cols]\n",
        "y = df['Target']\n",
        "\n",
        "# ---------- 9) Train/test split ----------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "# ---------- 10) Balance training set with SMOTE (optional but helpful) ----------\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# ---------- 11) Train classifier ----------\n",
        "clf = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42)\n",
        "clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# ---------- 12) Evaluate ----------\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"\\nClassification Report (Compliance as target):\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature importances\n",
        "importances = pd.Series(clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
        "print(\"\\nFeature importances:\\n\", importances)\n",
        "\n",
        "# ---------- 13) Example: cold-start prediction for a NEW supplier ----------\n",
        "# For cold-start we only need item category, quantity, unit_price, negotiated_price, order_date.\n",
        "# Provide a dict for new supplier onboarding attributes:\n",
        "new_supplier_info = {\n",
        "    'Item_Category': 'Office Supplies',   # must be one of valid_categories (or we map unknown -> mode)\n",
        "    'Quantity': 500,\n",
        "    'Unit_Price': 25.0,\n",
        "    'Negotiated_Price': 23.0,\n",
        "    'Order_Date': '2024-07-10'\n",
        "}\n",
        "\n",
        "# Safe mapping for category: if unseen, map to most frequent category\n",
        "cat_val = new_supplier_info['Item_Category']\n",
        "if cat_val not in valid_categories:\n",
        "    print(f\"Warning: category '{cat_val}' not in training categories. Mapping to mode: {valid_categories[0]}\")\n",
        "    cat_val = valid_categories[0]\n",
        "\n",
        "# Build feature row (same transforms)\n",
        "order_date = pd.to_datetime(new_supplier_info['Order_Date'], errors='coerce')\n",
        "oy = order_date.year if pd.notnull(order_date) else 0\n",
        "om = order_date.month if pd.notnull(order_date) else 0\n",
        "od = order_date.dayofweek if pd.notnull(order_date) else 0\n",
        "\n",
        "unit_price = float(new_supplier_info['Unit_Price'])\n",
        "neg_price = float(new_supplier_info.get('Negotiated_Price', unit_price))\n",
        "qty = float(new_supplier_info['Quantity'])\n",
        "price_diff = unit_price - neg_price\n",
        "price_ratio = neg_price / (unit_price + 1e-9)\n",
        "\n",
        "row = [\n",
        "    int(le_cat.transform([cat_val])[0]),\n",
        "    qty,\n",
        "    unit_price,\n",
        "    neg_price,\n",
        "    price_diff,\n",
        "    price_ratio,\n",
        "    int(oy),\n",
        "    int(om),\n",
        "    int(od)\n",
        "]\n",
        "\n",
        "# scale and predict cluster, then assemble final row including cluster\n",
        "row_scaled = scaler.transform([row])                # scaler expects same order used earlier\n",
        "pred_cluster = int(kmeans.predict(row_scaled)[0])\n",
        "\n",
        "# create final feature vector including cluster\n",
        "final_row = np.array(row + [pred_cluster]).reshape(1, -1)\n",
        "pred_label = clf.predict(final_row)[0]\n",
        "prob = clf.predict_proba(final_row)[0]\n",
        "\n",
        "print(\"\\nCold-start prediction for NEW supplier attributes:\")\n",
        "print(new_supplier_info)\n",
        "print(\"Assigned cluster:\", pred_cluster)\n",
        "print(\"Predicted Compliance (1 = reliable / yes):\", int(pred_label))\n",
        "print(\"Prediction probabilities (class 0 = No, class 1 = Yes):\", prob)\n",
        "\n",
        "# ---------- 14) Save models/artifacts (optional) ----------\n",
        "# You may want to persist label encoder, scaler, kmeans, and classifier for production use.\n",
        "# e.g. with joblib:\n",
        "# import joblib\n",
        "# joblib.dump(le_cat, 'le_item_category.joblib')\n",
        "# joblib.dump(scaler, 'scaler.joblib')\n",
        "# joblib.dump(kmeans, 'kmeans.joblib')\n",
        "# joblib.dump(clf, 'rf_compliance.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg3u41ZS-1Ft",
        "outputId": "48b89830-bfad-4fa0-a387-bf6e63279306"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Item_Category values: ['Electronics', 'MRO', 'Office Supplies', 'Packaging', 'Raw Materials']\n",
            "\n",
            "Classification Report (Compliance as target):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.32      0.27        28\n",
            "           1       0.84      0.77      0.80       128\n",
            "\n",
            "    accuracy                           0.69       156\n",
            "   macro avg       0.54      0.55      0.54       156\n",
            "weighted avg       0.73      0.69      0.71       156\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9 19]\n",
            " [29 99]]\n",
            "\n",
            "Feature importances:\n",
            " Quantity             0.149184\n",
            "Unit_Price           0.126261\n",
            "Price_Diff           0.117688\n",
            "Negotiated_Price     0.110932\n",
            "Cluster              0.106815\n",
            "Order_Month          0.105682\n",
            "Price_Ratio          0.096784\n",
            "Order_DayOfWeek      0.090732\n",
            "Item_Category_enc    0.052278\n",
            "Order_Year           0.043645\n",
            "dtype: float64\n",
            "\n",
            "Cold-start prediction for NEW supplier attributes:\n",
            "{'Item_Category': 'Office Supplies', 'Quantity': 500, 'Unit_Price': 25.0, 'Negotiated_Price': 23.0, 'Order_Date': '2024-07-10'}\n",
            "Assigned cluster: 2\n",
            "Predicted Compliance (1 = reliable / yes): 0\n",
            "Prediction probabilities (class 0 = No, class 1 = Yes): [0.69241792 0.30758208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Reload data\n",
        "df = pd.read_csv(\"Procurement KPI Analysis Dataset.csv\")\n",
        "\n",
        "# Dates\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
        "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], errors='coerce')\n",
        "\n",
        "# Filter valid Compliance values\n",
        "df['Compliance'] = df['Compliance'].astype(str).str.strip().str.lower()\n",
        "df = df[df['Compliance'].isin(['yes','no'])]\n",
        "df['Target'] = (df['Compliance'] == 'yes').astype(int)\n",
        "\n",
        "# Features\n",
        "df['Order_Year'] = df['Order_Date'].dt.year.fillna(0).astype(int)\n",
        "df['Order_Month'] = df['Order_Date'].dt.month.fillna(0).astype(int)\n",
        "df['Order_DayOfWeek'] = df['Order_Date'].dt.dayofweek.fillna(0).astype(int)\n",
        "\n",
        "# Delivery delay (new feature)\n",
        "df['Delivery_Delay'] = (df['Delivery_Date'] - df['Order_Date']).dt.days.fillna(0)\n",
        "\n",
        "# Price engineering\n",
        "df['Unit_Price'] = pd.to_numeric(df['Unit_Price'], errors='coerce')\n",
        "df['Negotiated_Price'] = pd.to_numeric(df['Negotiated_Price'], errors='coerce').fillna(df['Unit_Price'])\n",
        "df['Price_Diff'] = df['Unit_Price'] - df['Negotiated_Price']\n",
        "df['Price_Discount'] = df['Price_Diff'] / (df['Unit_Price'] + 1e-9)\n",
        "\n",
        "# Encode category\n",
        "le_cat = LabelEncoder()\n",
        "df['Item_Category_enc'] = le_cat.fit_transform(df['Item_Category'].astype(str))\n",
        "\n",
        "# Drop missing critical rows\n",
        "df = df.dropna(subset=['Unit_Price','Quantity'])\n",
        "\n",
        "# Clustering\n",
        "feat_for_cluster = ['Item_Category_enc','Quantity','Unit_Price','Negotiated_Price',\n",
        "                    'Order_Year','Order_Month','Order_DayOfWeek']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[feat_for_cluster])\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Final features\n",
        "feature_cols = ['Item_Category_enc','Quantity','Unit_Price','Negotiated_Price',\n",
        "                'Price_Diff','Price_Discount','Order_Year','Order_Month',\n",
        "                'Order_DayOfWeek','Delivery_Delay','Cluster']\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['Target']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=42)\n",
        "\n",
        "# XGBoost Classifier with class imbalance handling\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=(len(y_train[y_train==0]) / len(y_train[y_train==1])),\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Improved Model with XGBoost:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature importance\n",
        "importances = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
        "print(\"\\nFeature importances:\\n\", importances)\n",
        "\n",
        "# Example cold-start prediction\n",
        "new_supplier = {\n",
        "    'Item_Category': 'Office Supplies',\n",
        "    'Quantity': 500,\n",
        "    'Unit_Price': 25.0,\n",
        "    'Negotiated_Price': 23.0,\n",
        "    'Order_Date': '2024-07-10',\n",
        "    'Delivery_Date': '2024-07-20'\n",
        "}\n",
        "\n",
        "order_date = pd.to_datetime(new_supplier['Order_Date'])\n",
        "delivery_date = pd.to_datetime(new_supplier['Delivery_Date'])\n",
        "features = {\n",
        "    'Item_Category_enc': le_cat.transform([new_supplier['Item_Category']])[0],\n",
        "    'Quantity': new_supplier['Quantity'],\n",
        "    'Unit_Price': new_supplier['Unit_Price'],\n",
        "    'Negotiated_Price': new_supplier['Negotiated_Price'],\n",
        "    'Price_Diff': new_supplier['Unit_Price'] - new_supplier['Negotiated_Price'],\n",
        "    'Price_Discount': (new_supplier['Unit_Price'] - new_supplier['Negotiated_Price'])/new_supplier['Unit_Price'],\n",
        "    'Order_Year': order_date.year,\n",
        "    'Order_Month': order_date.month,\n",
        "    'Order_DayOfWeek': order_date.dayofweek,\n",
        "    'Delivery_Delay': (delivery_date - order_date).days\n",
        "}\n",
        "\n",
        "# Add cluster\n",
        "row_for_cluster = scaler.transform([[features['Item_Category_enc'], features['Quantity'],\n",
        "                                     features['Unit_Price'], features['Negotiated_Price'],\n",
        "                                     features['Order_Year'], features['Order_Month'], features['Order_DayOfWeek']]])\n",
        "features['Cluster'] = kmeans.predict(row_for_cluster)[0]\n",
        "\n",
        "# Predict\n",
        "row = pd.DataFrame([features])\n",
        "pred = model.predict(row)[0]\n",
        "prob = model.predict_proba(row)[0]\n",
        "print(\"\\nNew Supplier Prediction (XGBoost):\", \"Reliable\" if pred==1 else \"Unreliable\")\n",
        "print(\"Probabilities:\", prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cywL6K_tCodh",
        "outputId": "f2c83af3-e8ca-4b01-8dd1-76347b745607"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:03:16] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved Model with XGBoost:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.32      0.30        28\n",
            "           1       0.85      0.81      0.83       128\n",
            "\n",
            "    accuracy                           0.72       156\n",
            "   macro avg       0.56      0.57      0.56       156\n",
            "weighted avg       0.74      0.72      0.73       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  9  19]\n",
            " [ 24 104]]\n",
            "\n",
            "Feature importances:\n",
            " Order_Month          0.111764\n",
            "Order_Year           0.107259\n",
            "Cluster              0.103360\n",
            "Quantity             0.093580\n",
            "Delivery_Delay       0.093160\n",
            "Price_Diff           0.090039\n",
            "Price_Discount       0.082555\n",
            "Item_Category_enc    0.082196\n",
            "Unit_Price           0.079643\n",
            "Order_DayOfWeek      0.079172\n",
            "Negotiated_Price     0.077272\n",
            "dtype: float32\n",
            "\n",
            "New Supplier Prediction (XGBoost): Unreliable\n",
            "Probabilities: [0.5433933 0.4566067]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Predict probabilities for class 1 (Reliable)\n",
        "y_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Default threshold is 0.5 â†’ let's check PR curve to find a better cutoff\n",
        "prec, rec, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Choose threshold where recall for class 0 improves (say ~0.4)\n",
        "optimal_threshold = 0.4\n",
        "\n",
        "y_pred_adjusted = (y_proba > optimal_threshold).astype(int)\n",
        "\n",
        "print(f\"\\nClassification Report with Adjusted Threshold ({optimal_threshold}):\")\n",
        "print(classification_report(y_test, y_pred_adjusted))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_adjusted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbZdHTgXDSD3",
        "outputId": "6b6f29fc-85e9-410b-e01a-12ae6b54d242"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report with Adjusted Threshold (0.4):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.25      0.27        28\n",
            "           1       0.84      0.88      0.86       128\n",
            "\n",
            "    accuracy                           0.76       156\n",
            "   macro avg       0.57      0.56      0.57       156\n",
            "weighted avg       0.75      0.76      0.75       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  7  21]\n",
            " [ 16 112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Define parameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'subsample': uniform(0.7, 0.3),\n",
        "    'colsample_bytree': uniform(0.7, 0.3),\n",
        "    'gamma': uniform(0, 5),\n",
        "    'min_child_weight': randint(1, 6)\n",
        "}\n",
        "\n",
        "# Randomized search\n",
        "xgb_tuned = XGBClassifier(\n",
        "    scale_pos_weight=(len(y_train[y_train==0]) / len(y_train[y_train==1])),\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    xgb_tuned,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,  # number of random combinations to try\n",
        "    scoring='f1_macro',  # to balance both classes\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Parameters from RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(\"\\nClassification Report (Tuned Model):\")\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIHGc2BwD-GC",
        "outputId": "0fcbb3f8-5e60-4a15-8f01-1a8fdeb3890c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "\n",
            "Best Parameters from RandomizedSearchCV:\n",
            "{'colsample_bytree': np.float64(0.846833395335222), 'gamma': np.float64(0.2689151214665181), 'learning_rate': np.float64(0.1966409426915387), 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 366, 'subsample': np.float64(0.8706901871157914)}\n",
            "\n",
            "Classification Report (Tuned Model):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.29      0.24        28\n",
            "           1       0.83      0.77      0.80       128\n",
            "\n",
            "    accuracy                           0.68       156\n",
            "   macro avg       0.52      0.53      0.52       156\n",
            "weighted avg       0.72      0.68      0.70       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 8 20]\n",
            " [30 98]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "y_proba = best_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "best_thresh, best_f1 = 0.5, 0\n",
        "for t in np.arange(0.1, 0.9, 0.05):\n",
        "    y_pred_thresh = (y_proba > t).astype(int)\n",
        "    f1_class0 = f1_score(y_test, y_pred_thresh, pos_label=0)\n",
        "    if f1_class0 > best_f1:\n",
        "        best_f1 = f1_class0\n",
        "        best_thresh = t\n",
        "\n",
        "print(f\"Best threshold for class 0: {best_thresh}, F1 (class 0): {best_f1}\")\n",
        "\n",
        "# Apply best threshold\n",
        "y_pred_opt = (y_proba > best_thresh).astype(int)\n",
        "print(\"\\nClassification Report (Optimized Threshold):\")\n",
        "print(classification_report(y_test, y_pred_opt))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_opt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdrOXwAbECmg",
        "outputId": "f803c6e9-454b-4acd-ab44-a39e8913f03b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold for class 0: 0.8000000000000002, F1 (class 0): 0.3448275862068966\n",
            "\n",
            "Classification Report (Optimized Threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.71      0.34        28\n",
            "           1       0.88      0.47      0.61       128\n",
            "\n",
            "    accuracy                           0.51       156\n",
            "   macro avg       0.55      0.59      0.48       156\n",
            "weighted avg       0.76      0.51      0.56       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[20  8]\n",
            " [68 60]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[('rf', clf), ('xgb', best_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "ensemble.fit(X_train, y_train)\n",
        "y_pred_ens = ensemble.predict(X_test)\n",
        "\n",
        "print(\"\\nClassification Report (Ensemble RF+XGB):\")\n",
        "print(classification_report(y_test, y_pred_ens))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VvICXorEW1I",
        "outputId": "c11f72f6-b5c3-4b28-8358-cef106808566"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Ensemble RF+XGB):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.21      0.24        28\n",
            "           1       0.83      0.87      0.85       128\n",
            "\n",
            "    accuracy                           0.75       156\n",
            "   macro avg       0.55      0.54      0.54       156\n",
            "weighted avg       0.73      0.75      0.74       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  6  22]\n",
            " [ 17 111]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df.Target==1]\n",
        "df_minority = df[df.Target==0]\n",
        "\n",
        "df_majority_down = resample(df_majority,\n",
        "                            replace=False,\n",
        "                            n_samples=len(df_minority)*2,  # make it balanced or 2:1 ratio\n",
        "                            random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_majority_down, df_minority])\n"
      ],
      "metadata": {
        "id": "KPa-ArqHEaBn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Continue from your code ----------------\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Features (same as before)\n",
        "feature_cols = ['Item_Category_enc','Quantity','Unit_Price','Negotiated_Price',\n",
        "                'Price_Diff','Price_Discount','Order_Year','Order_Month',\n",
        "                'Order_DayOfWeek','Delivery_Delay','Cluster']\n",
        "\n",
        "X_bal = df_balanced[feature_cols]\n",
        "y_bal = df_balanced['Target']\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(\n",
        "    X_bal, y_bal, test_size=0.2, stratify=y_bal, random_state=42\n",
        ")\n",
        "\n",
        "# Retrain model (try XGBoost here)\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "balanced_model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "balanced_model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_bal = balanced_model.predict(X_test_bal)\n",
        "print(\"\\nClassification Report (Balanced Training):\")\n",
        "print(classification_report(y_test_bal, y_pred_bal))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_bal, y_pred_bal))\n",
        "\n",
        "# Predict probabilities to allow threshold adjustment later\n",
        "y_proba_bal = balanced_model.predict_proba(X_test_bal)[:,1]\n",
        "\n",
        "# ---------------- Example Cold-Start Prediction ----------------\n",
        "new_supplier = {\n",
        "    'Item_Category': 'Office Supplies',\n",
        "    'Quantity': 500,\n",
        "    'Unit_Price': 25.0,\n",
        "    'Negotiated_Price': 23.0,\n",
        "    'Order_Date': '2024-07-10',\n",
        "    'Delivery_Date': '2024-07-20'\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "order_date = pd.to_datetime(new_supplier['Order_Date'])\n",
        "delivery_date = pd.to_datetime(new_supplier['Delivery_Date'])\n",
        "\n",
        "features = {\n",
        "    'Item_Category_enc': le_cat.transform([new_supplier['Item_Category']])[0],\n",
        "    'Quantity': new_supplier['Quantity'],\n",
        "    'Unit_Price': new_supplier['Unit_Price'],\n",
        "    'Negotiated_Price': new_supplier['Negotiated_Price'],\n",
        "    'Price_Diff': new_supplier['Unit_Price'] - new_supplier['Negotiated_Price'],\n",
        "    'Price_Discount': (new_supplier['Unit_Price'] - new_supplier['Negotiated_Price'])/new_supplier['Unit_Price'],\n",
        "    'Order_Year': order_date.year,\n",
        "    'Order_Month': order_date.month,\n",
        "    'Order_DayOfWeek': order_date.dayofweek,\n",
        "    'Delivery_Delay': (delivery_date - order_date).days\n",
        "}\n",
        "\n",
        "# Predict cluster (same way as before)\n",
        "row_for_cluster = scaler.transform([[features['Item_Category_enc'], features['Quantity'],\n",
        "                                     features['Unit_Price'], features['Negotiated_Price'],\n",
        "                                     features['Order_Year'], features['Order_Month'], features['Order_DayOfWeek']]])\n",
        "features['Cluster'] = kmeans.predict(row_for_cluster)[0]\n",
        "\n",
        "row = pd.DataFrame([features])\n",
        "pred_bal = balanced_model.predict(row)[0]\n",
        "prob_bal = balanced_model.predict_proba(row)[0]\n",
        "\n",
        "print(\"\\nNew Supplier Prediction (Balanced Model):\", \"Reliable\" if pred_bal==1 else \"Unreliable\")\n",
        "print(\"Probabilities:\", prob_bal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an8zEn5SEeMZ",
        "outputId": "3ee187e9-e846-44bd-a81d-b636bded0ba5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Balanced Training):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.43      0.49        28\n",
            "           1       0.74      0.84      0.79        55\n",
            "\n",
            "    accuracy                           0.70        83\n",
            "   macro avg       0.66      0.63      0.64        83\n",
            "weighted avg       0.68      0.70      0.69        83\n",
            "\n",
            "Confusion Matrix:\n",
            " [[12 16]\n",
            " [ 9 46]]\n",
            "\n",
            "New Supplier Prediction (Balanced Model): Reliable\n",
            "Probabilities: [0.18783075 0.81216925]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Predict probabilities for class 1 (Reliable)\n",
        "y_proba_bal = balanced_model.predict_proba(X_test_bal)[:,1]\n",
        "\n",
        "best_thresh, best_f1 = 0.5, 0\n",
        "for t in np.arange(0.2, 0.8, 0.05):  # sweep thresholds\n",
        "    y_pred_thresh = (y_proba_bal > t).astype(int)\n",
        "    f1_class0 = f1_score(y_test_bal, y_pred_thresh, pos_label=0)\n",
        "    if f1_class0 > best_f1:\n",
        "        best_f1 = f1_class0\n",
        "        best_thresh = t\n",
        "\n",
        "print(f\"\\nBest threshold for class 0: {best_thresh}, F1 (class 0): {best_f1:.3f}\")\n",
        "\n",
        "# Apply best threshold\n",
        "y_pred_opt = (y_proba_bal > best_thresh).astype(int)\n",
        "print(\"\\nClassification Report (Optimized Threshold):\")\n",
        "print(classification_report(y_test_bal, y_pred_opt))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_bal, y_pred_opt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRrXa7r9EsVE",
        "outputId": "f17fadac-5ff6-4e46-882a-188da13e2f53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best threshold for class 0: 0.44999999999999996, F1 (class 0): 0.500\n",
            "\n",
            "Classification Report (Optimized Threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.43      0.50        28\n",
            "           1       0.75      0.85      0.80        55\n",
            "\n",
            "    accuracy                           0.71        83\n",
            "   macro avg       0.67      0.64      0.65        83\n",
            "weighted avg       0.70      0.71      0.70        83\n",
            "\n",
            "Confusion Matrix:\n",
            " [[12 16]\n",
            " [ 8 47]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE = \"/content/Procurement KPI Analysis Dataset.csv\"\n",
        "df = pd.read_csv(FILE)"
      ],
      "metadata": {
        "id": "Voot_IKvHCtt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# --- Assume df is loaded procurement dataset ---\n",
        "\n",
        "# Parse dates\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
        "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'])\n",
        "\n",
        "# New Features\n",
        "df['Price_Ratio'] = df['Negotiated_Price'] / df['Unit_Price']\n",
        "df['Discount_Amount'] = df['Unit_Price'] - df['Negotiated_Price']\n",
        "df['Total_Cost'] = df['Quantity'] * df['Negotiated_Price']\n",
        "df['High_Value_Flag'] = (df['Total_Cost'] > df['Total_Cost'].quantile(0.75)).astype(int)\n",
        "df['Bulk_Order_Flag'] = (df['Quantity'] > df['Quantity'].quantile(0.75)).astype(int)\n",
        "df['Order_Year'] = df['Order_Date'].dt.year\n",
        "df['Order_Month'] = df['Order_Date'].dt.month\n",
        "df['Order_DayOfWeek'] = df['Order_Date'].dt.dayofweek\n",
        "df['Weekend_Order'] = df['Order_DayOfWeek'].isin([5,6]).astype(int)\n",
        "df['Month_Quarter'] = df['Order_Date'].dt.quarter\n",
        "df['Delivery_Delay'] = (df['Delivery_Date'] - df['Order_Date']).dt.days\n",
        "df['Seasonal_Flag'] = df['Order_Month'].isin([11,12]).astype(int)  # example: year-end rush\n",
        "\n",
        "# Encode Item Category\n",
        "le_cat = LabelEncoder()\n",
        "df['Item_Category_enc'] = le_cat.fit_transform(df['Item_Category'])\n",
        "\n",
        "# Target = Compliance (Yes=1, No=0)\n",
        "df['Target'] = df['Compliance'].map({'Yes':1, 'No':0})\n",
        "\n",
        "# Select features\n",
        "feature_cols = [\n",
        "    'Item_Category_enc','Quantity','Unit_Price','Negotiated_Price',\n",
        "    'Price_Ratio','Discount_Amount','Total_Cost','High_Value_Flag','Bulk_Order_Flag',\n",
        "    'Order_Year','Order_Month','Order_DayOfWeek','Weekend_Order','Month_Quarter',\n",
        "    'Delivery_Delay','Seasonal_Flag'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['Target']\n",
        "\n",
        "# Balance dataset (downsample majority class)\n",
        "from sklearn.utils import resample\n",
        "df_majority = df[df.Target==1]\n",
        "df_minority = df[df.Target==0]\n",
        "\n",
        "df_majority_down = resample(df_majority,\n",
        "                            replace=False,\n",
        "                            n_samples=len(df_minority)*2,\n",
        "                            random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_majority_down, df_minority]).sample(frac=1, random_state=42)\n",
        "\n",
        "X_bal = df_balanced[feature_cols]\n",
        "y_bal = df_balanced['Target']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, stratify=y_bal, random_state=42)\n",
        "\n",
        "# Train XGBoost with engineered features\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nClassification Report (Feature Engineered):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature importances\n",
        "importances = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
        "print(\"\\nFeature Importances:\\n\", importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DqwKkZXFTzX",
        "outputId": "27985f70-2c52-4a0b-9b60-f2b41166d2e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Feature Engineered):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.32      0.39        28\n",
            "           1       0.71      0.84      0.77        55\n",
            "\n",
            "    accuracy                           0.66        83\n",
            "   macro avg       0.60      0.58      0.58        83\n",
            "weighted avg       0.64      0.66      0.64        83\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 9 19]\n",
            " [ 9 46]]\n",
            "\n",
            "Feature Importances:\n",
            " Order_DayOfWeek      0.092583\n",
            "Discount_Amount      0.090265\n",
            "Unit_Price           0.083290\n",
            "Order_Month          0.082059\n",
            "Total_Cost           0.078383\n",
            "Price_Ratio          0.071361\n",
            "Item_Category_enc    0.070233\n",
            "Order_Year           0.069315\n",
            "Delivery_Delay       0.069109\n",
            "Seasonal_Flag        0.068319\n",
            "Negotiated_Price     0.067598\n",
            "Quantity             0.059006\n",
            "Weekend_Order        0.058952\n",
            "Month_Quarter        0.028255\n",
            "Bulk_Order_Flag      0.011272\n",
            "High_Value_Flag      0.000000\n",
            "dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# --- Feature Engineering ---\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
        "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'])\n",
        "\n",
        "df['Price_Ratio'] = df['Negotiated_Price'] / df['Unit_Price']\n",
        "df['Discount_Amount'] = df['Unit_Price'] - df['Negotiated_Price']\n",
        "df['Total_Cost'] = df['Quantity'] * df['Negotiated_Price']\n",
        "df['Order_Year'] = df['Order_Date'].dt.year\n",
        "df['Order_Month'] = df['Order_Date'].dt.month\n",
        "df['Order_DayOfWeek'] = df['Order_Date'].dt.dayofweek\n",
        "df['Weekend_Order'] = df['Order_DayOfWeek'].isin([5,6]).astype(int)\n",
        "df['Month_Quarter'] = df['Order_Date'].dt.quarter\n",
        "df['Delivery_Delay'] = (df['Delivery_Date'] - df['Order_Date']).dt.days\n",
        "df['Seasonal_Flag'] = df['Order_Month'].isin([11,12]).astype(int)\n",
        "\n",
        "# Encode Item Category\n",
        "le_cat = LabelEncoder()\n",
        "df['Item_Category_enc'] = le_cat.fit_transform(df['Item_Category'])\n",
        "\n",
        "# Target = Compliance (Yes=1, No=0)\n",
        "df['Target'] = df['Compliance'].map({'Yes':1, 'No':0})\n",
        "\n",
        "# Features\n",
        "feature_cols = [\n",
        "    'Item_Category_enc','Quantity','Unit_Price','Negotiated_Price',\n",
        "    'Price_Ratio','Discount_Amount','Total_Cost',\n",
        "    'Order_Year','Order_Month','Order_DayOfWeek','Weekend_Order','Month_Quarter',\n",
        "    'Delivery_Delay','Seasonal_Flag'\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['Target']\n",
        "\n",
        "# --- Train-Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# --- Cost-Sensitive XGBoost ---\n",
        "scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])  # weight minority class\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    scale_pos_weight=scale_pos_weight\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Default Evaluation ---\n",
        "y_pred_default = model.predict(X_test)\n",
        "print(\"\\nDefault Threshold (0.5) Report:\")\n",
        "print(classification_report(y_test, y_pred_default))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
        "\n",
        "# --- Threshold Optimization ---\n",
        "y_proba = model.predict_proba(X_test)[:,1]\n",
        "best_thresh, best_f1 = 0.5, 0\n",
        "for t in np.arange(0.2, 0.8, 0.05):\n",
        "    y_pred_thresh = (y_proba > t).astype(int)\n",
        "    f1_class0 = f1_score(y_test, y_pred_thresh, pos_label=0)\n",
        "    if f1_class0 > best_f1:\n",
        "        best_f1 = f1_class0\n",
        "        best_thresh = t\n",
        "\n",
        "print(f\"\\nBest threshold for class 0: {best_thresh:.2f}, F1(class 0): {best_f1:.3f}\")\n",
        "\n",
        "# --- Apply Optimized Threshold ---\n",
        "y_pred_opt = (y_proba > best_thresh).astype(int)\n",
        "print(\"\\nClassification Report (Optimized Threshold):\")\n",
        "print(classification_report(y_test, y_pred_opt))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_opt))\n",
        "\n",
        "# --- Feature Importances ---\n",
        "importances = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
        "print(\"\\nFeature Importances:\\n\", importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAraO5B8HDak",
        "outputId": "af1f8a04-4cc9-41ca-accf-02f46a85e984"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Default Threshold (0.5) Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.43      0.39        28\n",
            "           1       0.87      0.83      0.85       128\n",
            "\n",
            "    accuracy                           0.76       156\n",
            "   macro avg       0.61      0.63      0.62       156\n",
            "weighted avg       0.78      0.76      0.77       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 12  16]\n",
            " [ 22 106]]\n",
            "\n",
            "Best threshold for class 0: 0.45, F1(class 0): 0.414\n",
            "\n",
            "Classification Report (Optimized Threshold):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.43      0.41        28\n",
            "           1       0.87      0.86      0.87       128\n",
            "\n",
            "    accuracy                           0.78       156\n",
            "   macro avg       0.64      0.64      0.64       156\n",
            "weighted avg       0.79      0.78      0.78       156\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 12  16]\n",
            " [ 18 110]]\n",
            "\n",
            "Feature Importances:\n",
            " Month_Quarter        0.109470\n",
            "Order_Year           0.084605\n",
            "Order_Month          0.080003\n",
            "Unit_Price           0.076554\n",
            "Delivery_Delay       0.071301\n",
            "Item_Category_enc    0.070687\n",
            "Quantity             0.070228\n",
            "Negotiated_Price     0.070153\n",
            "Total_Cost           0.067566\n",
            "Seasonal_Flag        0.065511\n",
            "Weekend_Order        0.059172\n",
            "Discount_Amount      0.059079\n",
            "Price_Ratio          0.058254\n",
            "Order_DayOfWeek      0.057418\n",
            "dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBb0tk9XHwgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}